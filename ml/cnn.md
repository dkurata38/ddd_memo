# 畳み込みニューラルネットワーク
## 活用例
+ 画像や動画に表示されている物体が何がを判定する.
+ 画像のどこに物体があるかを検出する.
+ 学習した特徴量をもとに画像を生成.

## 畳み込みネットワークを構成するもの
### 畳み込み層
#### 畳み込み層とは
入力値とカーネルフィルタの重なりあった部分を出力する.
入力値にカーネルフィルタを重ねる.少しずつずらして畳み込む. 重なった部分の和が畳み込み層の出力.
具体的な計算
要素積の和
https://deepage.net/deep_learning/2016/11/07/convolutional_neural_network.html#convolutional-neural-network%E3%81%AE%E7%89%B9%E5%BE%B4
#### ゼロパディング
畳み込むと特徴マップの大きさが必ず小さくなってしまう.
もとの入力特徴マップの回りに0を並べることで, 出力サイズが小さくなることを抑えられる.

#### ストライド
フィルタをいくつずつずらすかを表す指標.

#### 入力サイズと出力サイズ
出力サイズ = (入力サイズ + 2 * ゼロパディング - カーネルサイズ) / ストライド + 1

#### パラメータの初期化
+ 重み (カーネルサイズ, 入力サイズ, 出力サイズ)
+ バイアス (出力サイズ)


### プーリング層
特徴マップを小さくするための層.
+ Maxプーリング フィルタ内の最大値を抽出する.
+ Averageプーリング フィルタ内の平均値を抽出する.

### 全結合層
#### パラメータの初期化
+ 重み 入力サイズ * 出力サイズ

### 出力層
出力チャンネル数はクラス数と一致する.


## CNNの再利用
CNNでは何層もネットワークを重ねて学習することになる. 一度学習させたモデルに対して別の出力をさせたい場合, 一から学習する必要はない.
CNNの浅い層（下層）では, エッジなどの局所的な特徴を学習しているので, 深い層（上層）のみを再学習すればよい.

## CNNの応用
[参考サイト](http://thunders1028.hatenablog.com/entry/2017/11/01/035609)

### 転置畳み込み層
畳み込み層とは逆に特徴マップを大きくする層.
特徴マップを拡大した上で畳み込みを行う.

### VGG
小さいフィルターを持つ畳み込み層を2〜4つ連続して重ね、それをプーリング層でサイズを半分にするというのを繰り返し行う構造が特徴。大きいフィルターで画像を一気に畳み込むよりも小さいフィルターを何個も畳み込む(=層を深くする)方が特徴をより良く抽出できるらしい。バッチ正規化は使わないらしい。
